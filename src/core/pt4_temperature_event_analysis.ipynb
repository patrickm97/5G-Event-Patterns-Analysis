{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature Use Case (l001_bb) analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list files in input folder\n",
    "print(os.listdir('../input'))\n",
    "# number of rows in loo1_bb: 898147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read datetime_id and use_case_id columns from l001_bb.csv\n",
    "path = '../input/l001_bb.csv'\n",
    "\n",
    "# read only the header to determine the selected columns\n",
    "header_data = pd.read_csv(path, nrows=0)\n",
    "\n",
    "# dictionary to store the indexes of the selected columns\n",
    "dic_selected_columns = {}\n",
    "\n",
    "# list with desired columns\n",
    "desired_columns = ['datetime_id', 'use_case_id']\n",
    "\n",
    "# fill column indexes in the dictionary\n",
    "for col_name in desired_columns:\n",
    "    if col_name in header_data.columns:\n",
    "        col_index = header_data.columns.get_loc(col_name)\n",
    "        dic_selected_columns[col_name] = col_index\n",
    "\n",
    "# if the UC has both datetimes with and without time zone, delete local_datetime\n",
    "if 'datetime_id' in dic_selected_columns and 'local_datetime' in dic_selected_columns:\n",
    "    del dic_selected_columns['local_datetime']\n",
    "\n",
    "# list with dictionary values\n",
    "col_indexes = list(dic_selected_columns.values())\n",
    "\n",
    "print(f'Selected columns: {dic_selected_columns}')\n",
    "print(f'Indexes of selected columns: {col_indexes}')\n",
    "\n",
    "print('\\nStarting file reading...')\n",
    "data = pd.read_csv(path, usecols=col_indexes)\n",
    "\n",
    "n_rows, n_cols = data.shape\n",
    "file_name = os.path.basename(path)\n",
    "print(f'File reading \"{file_name}\" finished, {n_rows} linhas e {n_cols} colunas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouped CSV file will be different depending on which of the following 2 cells below is executed (rounded in hours or days)\n",
    "If rounded in hours is executed, make changes in API call cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round datetime in hours\n",
    "# convert datetime_id to timestamp\n",
    "data['datetime_id'] = pd.to_datetime(data['datetime_id'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# round datetime\n",
    "data['datetime_id'] = data['datetime_id'].dt.round('H')\n",
    "\n",
    "# remove minutes and seconds from timestamp string\n",
    "data['datetime_id'] = data['datetime_id'].dt.strftime('%Y-%m-%d %H')\n",
    "print('datetime_id column rounded in hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round datetime in days\n",
    "# convert datetime_id to timestamp\n",
    "data['datetime_id'] = pd.to_datetime(data['datetime_id'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# round datetime\n",
    "data['datetime_id'] = data['datetime_id'].dt.floor('D')\n",
    "\n",
    "# remove hours, minutes and seconds from timestamp string\n",
    "data['datetime_id'] = data['datetime_id'].dt.strftime('%Y-%m-%d')\n",
    "print('datetime_id column rounded in days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pivot table with the number of ocurrences in each day\n",
    "grouped_data = data.groupby(['datetime_id', 'use_case_id']).size().reset_index(name='l001_bb')\n",
    "\n",
    "pivot_data = grouped_data.pivot(index='datetime_id', columns='use_case_id', values='l001_bb').fillna(0)\n",
    "pivot_data.reset_index(inplace=True)\n",
    "print('Grouped DataFrame created\\n')\n",
    "\n",
    "# sort datetime_id in ascending order\n",
    "pivot_data = pivot_data.sort_values(by='datetime_id')\n",
    "print('datetime_id column sorted in ascending order\\n')\n",
    "\n",
    "# output to a new file\n",
    "pivot_data.to_csv('../output/l001_bb_temperatures.csv', index=False)\n",
    "print('File \"l001_bb_temperatures.csv\" created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read grouped file\n",
    "path = '../output/l001_bb_temperatures.csv'\n",
    "\n",
    "print('\\nStarting file reading...')\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "n_rows, n_cols = data.shape\n",
    "file_name = os.path.basename(path)\n",
    "print(f'File reading \"{file_name}\" finished, {n_rows} rows and {n_cols} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open-Meteo API calls to get temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get temperatures in each day\n",
    "# convert datetime_id to timestamp\n",
    "data['datetime_id'] = pd.to_datetime(data['datetime_id'], format='%Y-%m-%d')\n",
    "\n",
    "# define min and max date rounded in days\n",
    "min_date = data['datetime_id'].min()\n",
    "min_date = min_date.date()\n",
    "\n",
    "max_date = data['datetime_id'].max()\n",
    "max_date = max_date.date()\n",
    "\n",
    "# latitude e longitude of São Paulo\n",
    "latitude = -23.5475\n",
    "longitude = -46.6361\n",
    "\n",
    "def apt_temperatures():\n",
    "    # API endpoint to get max temperature in each day\n",
    "    url = f'https://archive-api.open-meteo.com/v1/archive?latitude={latitude}&longitude={longitude}&start_date={min_date}&end_date={max_date}&daily=temperature_2m_max'\n",
    "    \n",
    "    # URL endpoint to get temperature in each hour of a given day (uncomment if using file grouped in hours)\n",
    "    # url = f'https://archive-api.open-meteo.com/v1/archive?latitude={latitude}&longitude={longitude}&start_date={min_date}&end_date={max_date}&hourly=temperature_2m'\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    print(response)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data_api = response.json()\n",
    "        #print(data_api)\n",
    "\n",
    "        # extract time and temperature lists from response data\n",
    "        list_times = data_api['daily']['time']\n",
    "        list_temperatures = data_api['daily']['temperature_2m_max']\n",
    "\n",
    "        # dictionary with key = datetime and value = temperature\n",
    "        dic_temperatures = {}\n",
    "\n",
    "        # add itens to dictionary\n",
    "        for time, temperature in zip(list_times, list_temperatures):\n",
    "            # uncomment if using datetime rounded in hours - formatar a data e hora no formato \"YYYY-MM-DD H\"\n",
    "            # datetime_str = time.split('T')[0] + ' ' + time.split('T')[1].split(':')[0]\n",
    "\n",
    "            # add temperature in the dictionary\n",
    "            dic_temperatures[time] = temperature\n",
    "        \n",
    "        return dic_temperatures\n",
    "    # return None if API call was unsuccessful\n",
    "    return None\n",
    "\n",
    "dic_temperatures = apt_temperatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature dictionary information\n",
    "print(f'Temperatures dictionary: {len(dic_temperatures)}\\n')\n",
    "\n",
    "print('First 5 values:')\n",
    "for i, (key, value) in enumerate(dic_temperatures.items()):\n",
    "    if i < 5: \n",
    "        print(f'Datetime: {key}, Temperature: {value}')\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datetime_id column back to string format, so it is compatible with JSON string from API response\n",
    "data['datetime_id'] = data['datetime_id'].dt.strftime('%Y-%m-%d')\n",
    "print('datetime_id column converted back to string format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplly temperatures to the respective datetime_id in DataFrame\n",
    "def get_temperature(row):\n",
    "    datetime_str = row['datetime_id']\n",
    "    if datetime_str in dic_temperatures:\n",
    "        return dic_temperatures[datetime_str]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "data['max_temperature_SP'] = data.apply(get_temperature, axis=1)\n",
    "print('max_temperature_SP column added for each detetime_id in DataFrame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first 5 temperatures\n",
    "print(data.loc[0:5,['datetime_id','max_temperature_SP']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print temperature in one specific date\n",
    "print(dic_temperatures['2023-04-25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature statistics\n",
    "data['max_temperature_SP'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file\n",
    "path = '../output/l001_bb_max_temperatures.csv'\n",
    "data.to_csv(path, index=False)\n",
    "print('File l001_bb_max_temperatures.csv created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file with max temperatures\n",
    "path = '../output/l001_bb_max_temperatures.csv'\n",
    "data = pd.read_csv(path)\n",
    "print('File reading finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot ocurrences of UC and temperature curve in a given date range\n",
    "\n",
    "# filter date range (hard-code)\n",
    "day = '2023-01-01'\n",
    "day = pd.Timestamp(day)\n",
    "\n",
    "# n range\n",
    "n = 31\n",
    "\n",
    "day_plus_n = day + timedelta(days=n)\n",
    "day_plus_n = day_plus_n.strftime('%Y-%m-%d')\n",
    "day = day.strftime('%Y-%m-%d')\n",
    "print(f'day: {day} | day+{n}: {day_plus_n}\\n')\n",
    "\n",
    "# filter DataFrame with the rows in date range\n",
    "data_scatter = data.query(f\"'{day}' <= datetime_id < '{day_plus_n}'\")\n",
    "\n",
    "#print(data_scatter['datetime_id'].values)\n",
    "\n",
    "# plot\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax1.scatter(data_scatter['datetime_id'], data_scatter['l001_bb'], color='b', label='Ocurrences')\n",
    "\n",
    "ax1.set_xlabel('Datetime')\n",
    "ax1.set_ylabel('l001_bb ocurrences')\n",
    "\n",
    "# set x axis label values\n",
    "ax1.set_xticks(data_scatter['datetime_id'].unique())\n",
    "# rotate x axis labels\n",
    "ax1.set_xticklabels(pd.to_datetime(data_scatter['datetime_id']).dt.strftime('%Y-%m-%d'), rotation=90, ha='right')\n",
    "\n",
    "################################# temperature curve #####################################\n",
    "degree = 3  # polynomial degree (adjust as necessary)\n",
    "coeffs = np.polyfit(np.arange(len(data_scatter)), data_scatter['max_temperature_SP'], degree)\n",
    "temperature_curve = np.polyval(coeffs, np.arange(len(data_scatter)))\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(data_scatter['datetime_id'], temperature_curve, color='r', label='Temperature (°C)', linestyle='--')\n",
    "#############################################################################################\n",
    "\n",
    "# secondary y axis configuration\n",
    "ax2.set_ylabel('Max Temperature (°C) in SP')\n",
    "ax2.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "# labels and legend\n",
    "ax1.set_title(f'Use Case l001_bb (temperature) - {day} to {day_plus_n}')\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
