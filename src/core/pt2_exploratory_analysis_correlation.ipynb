{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class distribution and correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../output/temporal_UCs.csv', delimiter=',')\n",
    "\n",
    "n_rows, n_cols = data.shape\n",
    "print(f'File reading \"temporal_UCs.csv\" finished, {n_rows} rows and {n_cols} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot with the class distribution\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "plt.title('Use Cases samples size')\n",
    "plt.ylabel('Sample')\n",
    "plt.xlabel('Use Case')\n",
    "data['use_case_id'].value_counts().sort_values().plot(kind='bar', rot=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare dataset for Linear Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pivot table from CSV with joined UCs (datetime in seconds)\n",
    "\n",
    "# convert datetime_id to timestamp\n",
    "data['datetime_id'] = pd.to_datetime(data['datetime_id'], unit='s')\n",
    "\n",
    "# group by datetime_id and count the number of ocurrences of each use_case_id\n",
    "data = data.groupby(['datetime_id', 'use_case_id']).size().unstack(fill_value=0).reset_index()\n",
    "print('Grouped DataFrame (datetime in seconds) created\\n')\n",
    "\n",
    "data.to_csv('../output/temporal_UCs_pivot_s.csv', index=False)\n",
    "print('\"temporal_UCs_pivot_s.csv\" created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pivot table from CSV with joined UCs (datetime in minutes)\n",
    "\n",
    "# convert datetime_id to timestamp\n",
    "data['datetime_id'] = pd.to_datetime(data['datetime_id'], unit='s')\n",
    "\n",
    "# round datetime in minutes\n",
    "data['datetime_id'] = data['datetime_id'].dt.round('Min')\n",
    "\n",
    "# remove the seconds from timestamp string\n",
    "data['datetime_id'] = data['datetime_id'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "# group by datetime_id and count the number of ocurrences of each use_case_id\n",
    "data_min = data.groupby(['datetime_id', 'use_case_id']).size().unstack(fill_value=0).reset_index()\n",
    "print('Grouped DataFrame (datetime in minutes) created\\n')\n",
    "\n",
    "data_min.to_csv('../output/temporal_UCs_pivot_min.csv', index=False)\n",
    "print('\"temporal_UCs_pivot_min.csv\" created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pivot table from CSV with joined UCs (datetime in hours)\n",
    "\n",
    "# convert datetime_id to timestamp\n",
    "data['datetime_id'] = pd.to_datetime(data['datetime_id'], unit='s')\n",
    "\n",
    "# round datetime in hours\n",
    "data['datetime_id'] = data['datetime_id'].dt.round('H')\n",
    "\n",
    "# remove seconds and minutes from timestamp string\n",
    "data['datetime_id'] = data['datetime_id'].dt.strftime('%Y-%m-%d %H')\n",
    "\n",
    "# group by datetime_id and count the number of ocurrences of each use_case_id\n",
    "data_min = data.groupby(['datetime_id', 'use_case_id']).size().unstack(fill_value=0).reset_index()\n",
    "print('Grouped DataFrame (datetime in hours) created\\n')\n",
    "\n",
    "data_min.to_csv('../output/temporal_UCs_pivot_hr.csv', index=False)\n",
    "print('\"temporal_UCs_pivot_hr.csv\" created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pivot table from CSV with joined UCs (datetime in days)\n",
    "\n",
    "# convert datetime_id to timestamp\n",
    "data['datetime_id'] = pd.to_datetime(data['datetime_id'], unit='s')\n",
    "\n",
    "# round datetime in days\n",
    "data['datetime_id'] = data['datetime_id'].dt.floor('D')\n",
    "\n",
    "# remove seconds and minutes from timestamp string\n",
    "data['datetime_id'] = data['datetime_id'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# group by datetime_id and count the number of ocurrences of each use_case_id\n",
    "data_min = data.groupby(['datetime_id', 'use_case_id']).size().unstack(fill_value=0).reset_index()\n",
    "print('Grouped DataFrame (datetime in days) created\\n')\n",
    "\n",
    "data_min.to_csv('./output/temporal_UCs_pivot_d.csv', index=False)\n",
    "print('\"temporal_UCs_pivot_d.csv\" created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CSV file grouped in seconds\n",
    "path = '../output/temporal_UCs_pivot_s.csv'\n",
    "data_s = pd.read_csv(path, delimiter=',')\n",
    "\n",
    "n_rows, n_cols = data_s.shape\n",
    "print(f'File reading \"temporal_UCs_pivot_s.csv\" finished, {n_rows} rows and {n_cols} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove datetime column so it doesn't show up in the plots\n",
    "data_s = data_s.drop(['datetime_id'], axis=1)\n",
    "print('datetime_id column removed from DataFrame')\n",
    "\n",
    "n_rows, n_cols = data_s.shape\n",
    "print(f'{n_rows} rows and {n_cols} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if executed, change data_s to data_min in Linear Correlation cells below\n",
    "# read CSV file grouped in minutes\n",
    "path = '../output/temporal_UCs_pivot_min.csv'\n",
    "data_min = pd.read_csv(path, delimiter=',')\n",
    "\n",
    "n_rows, n_colmns = data_min.shape\n",
    "print(f'File reading \"temporal_UCs_pivot_min.csv\" finished, {n_rows} rows and {n_cols} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONLY IF CELL ABOVE WAS EXECUTED\n",
    "# remove datetime column so it doesn't show up in the plots\n",
    "data_min = data_min.drop(['datetime_id'], axis=1)\n",
    "print('datetime_id column removed from DataFrame')\n",
    "\n",
    "n_rows, n_cols = data_min.shape\n",
    "print(f'{n_rows} rows and {n_cols} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Correlation execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc1 = 'l001_bb'\n",
    "uc2 = 'l083'\n",
    "# Pearson correlation betwwen 2 UCs\n",
    "pearson_corr = pearsonr(data_s[uc1], data_s[uc2])\n",
    "print(f'Pearson between {uc1} and {uc2}')\n",
    "print('Correlation = %.2f' % pearson_corr[0])\n",
    "print('p = %.1f' % pearson_corr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman correlation\n",
    "spearman_corr = spearmanr(data_s[uc1], data_s[uc2])\n",
    "print(f'Spearman between {uc1} and {uc2}')\n",
    "print('Correlation = %.2f' % spearman_corr[0])\n",
    "print('p = %.1f' % spearman_corr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kendall correlation\n",
    "kendall_corr = kendalltau(data_s[uc1], data_s[uc2])\n",
    "print(f'Kendall between {uc1} and {uc2}')\n",
    "print('Correlation = %.2f' % kendall_corr[0])\n",
    "print('p = %.1f' % kendall_corr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average correlation between the 2 selected UCs\n",
    "avg_corr = (pearson_corr[0] + spearman_corr[0] + kendall_corr[0]) / 3\n",
    "print(f'Average correlation between UCs {uc1} and {uc2}', end=' = ')\n",
    "print('%.2f' % avg_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc3 = 'l090'\n",
    "# correlation between 3 selected UCs (Pearson)\n",
    "corr_pearson = data[[uc1, uc2, uc3]].corr(method='pearson')\n",
    "print(corr_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between 3 selected UCs (Spearman)\n",
    "corr_spearman = data[[uc1, uc2, uc3]].corr(method='spearman')\n",
    "print(corr_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix (Pearson)\n",
    "corr_mat_pearson = data_s.corr(method='pearson')\n",
    "print(corr_mat_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix (Spearman)\n",
    "corr_mat_spearman = data_s.corr(method='spearman')\n",
    "print(corr_mat_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix (Kendall)\n",
    "corr_mat_kendall = data_s.corr(method='kendall')\n",
    "print(corr_mat_kendall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap (Pearson)\n",
    "sns.heatmap(corr_mat_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap (Pearson)\n",
    "sns.clustermap(corr_mat_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap (Spearman)\n",
    "sns.heatmap(corr_mat_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustered heatmap (Spearman)\n",
    "sns.clustermap(corr_mat_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustered heatmap (Kendall)\n",
    "sns.heatmap(corr_mat_kendall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustered heatmap (Kendall)\n",
    "sns.clustermap(corr_mat_kendall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
